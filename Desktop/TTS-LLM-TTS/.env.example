# TTS-LLM-TTS Environment Variables
# Copy this file to .env and fill in your API keys and configuration

# ==================== API KEYS ====================
# OpenAI API Key (for GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenRouter API Key (for free models like DeepSeek)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# HuggingFace Token (REQUIRED for Sesame CSM and other HF models)
HUGGING_FACE_TOKEN=your_huggingface_token_here

# ==================== DOCKER CONFIGURATION ====================
# Service Ports
STT_PORT=5001
LLM_PORT=5002
TTS_PORT=5003
MEMORY_PORT=5004
ORCHESTRATOR_PORT=5000
WEBUI_PORT=8080

# GPU Configuration
USE_GPU=true
NVIDIA_VISIBLE_DEVICES=all

# Model Cache Directory
CACHE_DIR=/cache

# Logging
LOG_LEVEL=INFO
PYTHONUNBUFFERED=1

# ==================== TTS CONFIGURATION ====================
# TTS Speaker ID (for Sesame CSM, default 4 for expressiva)
TTS_SPEAKER_ID=4

# ==================== BUILD OPTIONS ====================
# For local LLM builds
CMAKE_ARGS=-DLLAMA_CUBLAS=on
FORCE_CMAKE=1
